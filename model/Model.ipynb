{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flask pandas scikit-learn vaderSentiment nltk requests aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'your_newsapi_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_news(country):\n",
    "    url = f\"https://newsapi.org/v2/top-headlines?country={country}&apiKey={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['articles']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    articles = fetch_news('us')\n",
    "    for article in articles:\n",
    "        print(article['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalpha()]  \n",
    "    tokens = [word.lower() for word in tokens] \n",
    "    tokens = [word for word in tokens if word not in stop_words]  \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"The economy is doing well. Stock markets are up!\"\n",
    "    print(preprocess_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    if scores['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    text = \"The economy is doing well. Stock markets are up!\"\n",
    "    print(get_sentiment(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentiment_analysis import get_sentiment, analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_data = {\n",
    "    'GDP_growth_rate': {\n",
    "        'us': 2.3,\n",
    "        'uk': 1.8,\n",
    "        'de': 1.5,\n",
    "        'jp': 0.7,\n",
    "        'cn': 6.0,\n",
    "        'in': 5.5,\n",
    "        'fr': 1.7,\n",
    "        'it': 0.3,\n",
    "        'ca': 1.9,\n",
    "        'au': 2.2\n",
    "    },\n",
    "    'inflation_rate': {\n",
    "        'us': 1.5,\n",
    "        'uk': 2.1,\n",
    "        'de': 1.4,\n",
    "        'jp': 0.3,\n",
    "        'cn': 2.8,\n",
    "        'in': 3.8,\n",
    "        'fr': 1.3,\n",
    "        'it': 0.5,\n",
    "        'ca': 1.7,\n",
    "        'au': 1.6\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text_data, country_data):\n",
    "    features = []\n",
    "    for text, country in text_data:\n",
    "        sentiment = get_sentiment(text)\n",
    "        sentiment_score = analyzer.polarity_scores(text)['compound']\n",
    "        \n",
    "        gdp_growth = country_data['GDP_growth_rate'].get(country, 0.0)\n",
    "        inflation = country_data['inflation_rate'].get(country, 0.0)\n",
    "        \n",
    "        features.append({\n",
    "            'sentiment': sentiment,\n",
    "            'sentiment_score': sentiment_score,\n",
    "            'GDP_growth_rate': gdp_growth,\n",
    "            'inflation_rate': inflation\n",
    "        })\n",
    "    return pd.DataFrame(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    text_data = [\n",
    "        (\"The economy is doing well.\", 'us'),\n",
    "        (\"Stock markets are down.\", 'uk')\n",
    "    ]\n",
    "    features = extract_features(text_data, financial_data)\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'sentiment_score': [0.5, -0.3, 0.1, -0.8, 0.2],\n",
    "    'target': [0.01, -0.02, 0.005, -0.03, 0.008]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('target', axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(predictions, threshold=0.01):\n",
    "    recommendations = []\n",
    "    for i, pred in enumerate(predictions):\n",
    "        if pred > threshold:\n",
    "            recommendations.append(f\"Buy currency pair {i}\")\n",
    "        elif pred < -threshold:\n",
    "            recommendations.append(f\"Sell currency pair {i}\")\n",
    "        else:\n",
    "            recommendations.append(f\"Hold currency pair {i}\")\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    predictions = [0.02, -0.01, 0.005, -0.03, 0.008]\n",
    "    recommendations = generate_recommendations(predictions)\n",
    "    for rec in recommendations:\n",
    "        print(rec)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
